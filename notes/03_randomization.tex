\section{Randomization}

In the previous sections, we have only dealt with (non)-deterministic TMs. However, there are many important classes that relate a TM when using a probability, as we define below:

\begin{definition}
A \emph{probabilistic TM} (PTM) has two transition functions, and at each step we choose, independently with probability $\frac{1}{2}$, to apply one of the two functions, like a coin flip. We say that a PTM $M$ halts in $T(n)$ time if $M$ halts on all inputs $x$ within $T(|x|)$ steps, regardless of the choices made during execution.
\end{definition}

We can now define the probabilistic analog of $\P$, which is $\BPP$:
\begin{definition}
A language $L$ is in $\BPTIME(T(n))$ if there exists a PTM $M$ that decides $L$ in time $T(n)$, $M$ halts within $T(|x|)$ steps regardless of choices, and $\Pr[M(x) = L(x)] \ge \frac{2}{3}$. We define:
\[
\BPP = \bigcup_{c \ge 0}\BPTIME(n^c)
\]
\end{definition}

We also give an alternate definition for $\BPP$:
\begin{definition}
$L \in \BPP$ if there exists a poly-time TM verifier $M$ and a polynomial $p$ such that for all $x \in \{0, 1\}^*$, $\Pr[L(M) = L] \ge \frac{2}{3}$ where $M$ has certificates of size $p(|x|)$.
\end{definition}

\begin{theorem}
$\BPP \subseteq \Ppoly$.
\end{theorem}

This proof will use what is called as ``success amplification" - the essential idea is that, given we have polynomial time, we can make successive coin flips to reduce the error bound for $\BPP$ to even less error. We do this as follows:
\begin{itemize}
\item For a PTM $M$ that computes a language $L$ with error $\frac{1}{2} - \frac{1}{n^c}$, run $M$ for $k$ independent trials, and accept only if at least half of the trials accept. 
\item Define $X_i = 1$ if the $i$-th trial accepts, and 0 otherwise, and $X = \Sigma_1^k X_i$. 
\item Therefore, $\Pr[X_i = 1] \ge \frac{1}{2} + \frac{1}{n^c}$. Call this result $p$.
\item $\E[X] \ge pk$ for the same reasoning.
\item Call $\delta = 1-\frac{1}{2p}$.
\end{itemize}
Therefore, now we want to find the probability that the trials done above are incorrect, by using Chernoff bounds:
\begin{center}
$\Pr[X < (1-\delta)pk] \le \exp(\frac{-{(1-\frac{1}{2p})^2}pk}{2}) \le \exp(-\frac{k}{2n^{2c}})$
\end{center}
So, for $k$ a polynomial (i.e., $2n^{2c+d}$), we can have an exponentially small error bound. Now, onto the proof.

\begin{proof}
Let $L \in \BPP$. By success amplification, there is a poly-time TM $M$ such that $L(M) = L$ with error smaller than $2^{-n}$. Choose an $x \in \{0, 1\}^n$. Therefore, $\Pr[\text{$M$ computes incorrectly on $x$}] < \frac{1}{2^n}$. We can observe that:
\[
\Pr[\text{$M$ computes incorrectly on some $y \in \{0, 1\}^n$}] \le \Sigma_{x \in \{0, 1\}^n} \Pr[\text{$M$ computes incorrectly on $x$}] = 1
\]
Therefore, there are some coin flips where $M$ does not make any error on any $x \in \{0, 1\}^n$. All we need to do is convert $M$ into a circuit and hardwire these coin flips, which completes the proof. 
\end{proof}

\begin{theorem}[Sipser-G\'{a}cs]
$\BPP \subseteq \Sigma_2^\P \cap \Pi_2^\P$.
\end{theorem}

\begin{proof}
As before, assume that for an $L \in \BPP$ there is a poly-time TM $M$ such that $L(M) = L$ with error smaller than $2^{-n}$. Since $\BPP$ is closed under complement, we only need to show $\BPP \subseteq \Sigma_2^\P$.

\par For $x \in \{0, 1\}^n$, let $S_x$ be the set of certificates for which $M$ accepts $x$, and let $p$ be the polynomial that is the number of random bits $M$ uses. Therefore, either $|S_x| \ge (1-2^{-n})2^{p(n)}$, or $|S_x| \le 2^{p(n)-n}$, whether $x \in L$ or not. What we will show is that we can differentiate between these using only 2 quantifiers.

\par For $A \subseteq \{0, 1\}^{p(n)}$ and $b \in \{0, 1\}^{p(n)}$, define $A+b = \{a+b \colon a \in A\}$, where the operation is done $(\mod 2)$. Let $k = \lceil {p(n)/n} \rceil +1$. We will show the following:

\begin{enumerate}
\item For all $S \subseteq \{0, 1\}^{p(n)}$ and $|S| \le 2^{p(n)-n}$ and any $k$ vectors $\{u_i\}_{1 \le i \le k}$ with $u_i \in \{0, 1\}^{p(n)}$, we have that $\bigcup_{i=1}^{k} (S+u_i) \ne \{0, 1\}^{p(n)}$.

\item For all $S \subseteq \{0, 1\}^{p(n)}$ and $|S| \ge (1-2^{-n})2^{p(n)}$, there exist $k$ vectors $\{u_i\}_{1 \le i \le k}$ with $\bigcup_{i=1}^{k}(S+u_i) = \{0, 1\}^{p(n)}$.
\end{enumerate}
In other words, we can establish that $x \in L$ with only 2 quantifiers. Proving these implies that $\BPP \subseteq \Sigma_2^\P \cap \Pi_2^\P$. For the first proof, we have that $|S + u_i| = |S|$, so the union is at most $k|S| < 2^{p(n)}$ for large enough $n$.

\par For the second proof, if the $u_i$ are chosen independently randomly, then $\Pr[\bigcup_{i=1}^{k}(S+u_i) = \{0, 1\}] > 0$ will imply the proof. Let $B_r$ be the event that $r \notin \bigcup_{i=1}^{k}(S+u_i)$. This implies that we need to prove that $\Pr[\exists B_r] < 1$ for some $r \in \{0, 1\}^{p(n)}$. Equivalently, we can show that $\Pr[B_r] < 2^{-p(n)}$ for all $r$. 

\par Define $B_r^i$ the event that $r \notin S + u_i$ (equivalently, $r + u_i \notin S$). We can see that $B_r = \bigcap_{1 \le i \le k}B_{r}^i$. However, $r+u_i$ is uniformly chosen from $\{0, 1\}^{p(n)}$, so $r+u_i \in S$ with probability $\ge 1-2^{-n}$. Also, since the $B_r^i$ are independent for all $i$, we have $\Pr[B_r] = (\Pr[B_r^i])^k \le 2^{-nk} < 2^{-p(n)}$. 
\end{proof}

\subsection{$\RP, \coRP, \ZPP$}

\subsection*{Exercises}
\newcommand{\BPPpoly}{\BPP/\poly}
\begin{enumerate}
\item Show that $\BPPpoly = \Ppoly$. % http://zoo.cs.yale.edu/classes/cs468/fall12/468Solutions2.pdf
\item Show that if $\NP \subseteq \BPP$, then $\NP = \RP$. % http://www.inf.ed.ac.uk/teaching/courses/cmc/cw3_solns.pdf
\end{enumerate}